# Node-RED MCP Server 

Conecta Node-RED a LLMs via Model Context Protocol (MCP) para fluxos de IA inteligentes.

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.com/deploy/node-red-mcp)

> **üöÄ Template pronto para deploy no Railway** - Node-RED configurado com MCP (Model Context Protocol) para integra√ß√£o com LLMs

[üá∫üá∏ Read in English](README.md)

## üìã Descri√ß√£o do Projeto

Este projeto cont√©m uma estrutura Docker com dois containers principais que integram o Node-RED e o mcp-host para rodar o MCP Server (Model Context Protocol). O objetivo √© permitir que fluxos no Node-RED possam interagir com modelos LLM como o GPT-4 da OpenAI, usando um servidor MCP.

Essa primeira vers√£o suporta somente o modelo GPT-4 da OpenAI.

Voc√™ consegue rodar um MCP local e remoto.
Exemplo de um MCP remoto:

```bash
npx -y @smithery/cli@latest run @nickclyde/duckduckgo-mcp-server --key sua-chave-do-smithery
```

[üîó Encontre outros MCPs no smithery.io](https://smithery.io)

## üöÄ Templates Prontos para Deploy

### Node-RED MCP Template para Railway

Para facilitar o deploy e come√ßar rapidamente, criamos um template otimizado para o Railway:

**[üìã Ver Template Completo](node-red-docker/README.md)**

**Caracter√≠sticas do Template:**
- ‚úÖ **Deploy com um clique** no Railway
- ‚úÖ **Node-RED 4.0.0** pr√©-configurado
- ‚úÖ **MCP Tools Node** j√° instalado
- ‚úÖ **Configura√ß√£o autom√°tica** via vari√°veis de ambiente
- ‚úÖ **Backup autom√°tico** de fluxos e configura√ß√µes
- ‚úÖ **Monitoramento** integrado

**Como usar:**
1. Acesse o [README do Template](node-red-docker/README.md)
2. Clique no bot√£o "Deploy on Railway"
3. Configure suas vari√°veis de ambiente
4. Pronto! Node-RED rodando na nuvem

---

## ‚ñ∂Ô∏è Como Executar

### Passos para rodar o projeto via Docker Compose:

1. **Clone este reposit√≥rio:**
   ```bash
   git clone https://github.com/moises-paschoalick/node-red-mcp-server
   cd node-red-docker
   docker compose up -d
   ```

2. **Abra o projeto em:** http://localhost:1899/

3. **Instale o node mcp-tools**
   Para isso precisamos ter o node mcp-tools, instalar o node-red-contrib-mcp-tools na UI do Node-RED.

   **Op√ß√µes -> Gerenciar Paleta**
   **Instalar node-red-contrib-mcp-tools**
   [Imagem instala√ß√£o]

   [link do node-red-contrib-mcp-tools]
   link do projeto npm

4. **Configure o componente com a chave da OpenAI**
   [imagem do componente]

## üß± Estrutura dos Containers

- **`mcp-host`**  
  Componente feito em Node.js que faz a ponte (bridge) entre o Node-RED (via componente `mcp-tools`) e os MCP Servers.  
  Ele √© respons√°vel por intermediar a comunica√ß√£o entre o `mcp-client` (modelo LLM) e o `mcp-server` (entende a implementa√ß√£o das tools).

- **`mcp-server-demo`** (Node-RED)  
  Cont√©m o ambiente do Node-RED j√° configurado para se comunicar com o `mcp-host` usando o componente `mcp-tools`. √â um exemplo de um mcp-server feito em NodeJS para testar e verificar se o ambiente est√° funcional.

> **Importante**: no componente **mcp-tools** dentro do Node-RED, √© necess√°rio configurar a URL do MCP Host como:
> ```
> http://mcp-host:3000
> ```

---

## üì¶ Componentes

- **`mcp-host`**
  - Recebe chamadas do Node-RED via `mcp-tools`
  - Redireciona a solicita√ß√£o para o `mcp-client`
  - Encaminha o resultado para o `mcp-server` (local ou remoto)
  
- **`mcp-client`**
  - Realiza a comunica√ß√£o com um modelo de linguagem (LLM)
  - Atualmente usa o modelo `gpt-4o` da OpenAI
  - Pode ser modificado para usar outros modelos no futuro (ex: Claude, Gemini, LLaMA)

- **`mcp-server-demo`**
  - Um exemplo funcional de MCP Server rodando localmente
  - Cont√©m "tools" (ferramentas) que podem ser chamadas pelo modelo, como:
    - **Hello Tool**: responde com "Hello World"
    - **Local Time**: retorna a hora local do servidor
    - **Weather Tool**: consulta clima atual de S√£o Paulo via `wttr.in`

---

### Pr√©-requisitos

- Docker
- Docker Compose

### Endpoints para verificar a integridade no mcp-host 
http://localhost:3000/health

## Arquitetura

```
Node-RED Component ‚Üí mcp-host (Express.js) ‚Üí mcp-client ‚Üí mcp-server
                                                ‚Üì
                                           OpenAI API
```

### Componentes Detalhados

#### 1. **mcp-host** (Servidor Web)
- **Localiza√ß√£o:** `/mcp-host/`
- **Fun√ß√£o:** Servidor Express.js que orquestra as comunica√ß√µes
- **Porta:** 3000 (configur√°vel)
- **Endpoints:**
  - `POST /execute` - Executa prompts
  - `GET /health` - Status do servidor
  - `GET /tools` - Lista ferramentas dispon√≠veis
  - `POST /disconnect` - Desconecta sess√µes

#### 2. **mcp-client** (Cliente MCP)
- **Localiza√ß√£o:** `/mcp-client/`
- **Fun√ß√£o:** Classe que gerencia conex√µes com servidores MCP e OpenAI
- **Recursos:**
  - Conex√£o/desconex√£o autom√°tica
  - Gerenciamento de sess√µes
  - Convers√£o de ferramentas MCP para formato OpenAI
  - Execu√ß√£o de prompts com tool calling

#### 3. **mcp-server** (Servidor MCP)
- **Localiza√ß√£o:** `/mcp-server/`
- **Fun√ß√£o:** Implementa√ß√£o do servidor MCP com ferramentas e recursos
- **Ferramentas inclu√≠das:**
  - Hello Tool (exemplo)
  - Users Tool (API externa)
  - Textract Tool (an√°lise de imagens)

#### 4. **node-red-mcp-component** (Componente Node-RED)
- **Localiza√ß√£o:** `/node-red-mcp-component/`
- **Fun√ß√£o:** N√≥ customiz√°vel para Node-RED
- **Configura√ß√µes:**
  - URL do MCP Host
  - API Key da OpenAI
  - Comando do servidor MCP
  - Argumentos do servidor MCP
  - Session ID
  - Timeout

## Endpoints da API

### POST /execute

Executa um prompt atrav√©s do agente MCP.

**Corpo da Requisi√ß√£o:**
```json
{
  "prompt": "show hello world message",
  "apiKey": "sk-sua-chave-aqui",
  "serverCommand": "node",
  "serverArgs": ["../mcp-server/build/index.js"],
  "sessionId": "default"
}
```

**Resposta:**
```json
{
  "success": true,
  "response": "Hello, World! This is a tool response!",
  "toolsUsed": [...],
  "messages": [...]
}
```

### GET /health

Verifica o status do servidor.

**Resposta:**
```json
{
  "status": "ok",
  "timestamp": "2025-06-11T23:32:04.612Z",
  "activeClients": 0
}
```

### GET /tools

Lista ferramentas dispon√≠veis.

**Par√¢metros de Query:**
- `apiKey` - API Key da OpenAI
- `serverCommand` - Comando do servidor MCP
- `serverArgs` - Argumentos do servidor MCP

## Instala√ß√£o e Configura√ß√£o (sem Docker)

### 1. Preparar os Componentes

```bash
# Instalar depend√™ncias do mcp-server
cd mcp-server
npm install
npm run build

# Instalar depend√™ncias do mcp-client
cd ../mcp-client
npm install
npm run build

# Instalar depend√™ncias do mcp-host
cd ../mcp-host
npm install
```

### 2. Iniciar o MCP Host

```bash
cd mcp-host
npm start
```

O servidor rodar√° na porta 3000.

## üêõ Solu√ß√£o de Problemas

### Problemas Comuns

#### 1. Container n√£o inicia
```bash
# Verifique os logs
docker logs node-red-mcp

# Verifique se as portas est√£o dispon√≠veis
netstat -tulpn | grep :1899
```

#### 2. MCP Tools n√£o funciona
- Verifique se a API Key da OpenAI est√° correta
- Confirme se o MCP Host est√° acess√≠vel
- Verifique os logs do MCP Host

#### 3. Erro de permiss√µes
```bash
# Corrija as permiss√µes
docker exec -it node-red-mcp chown -R node-red:node-red /data
```

### Logs e Debug

```bash
# Logs do Node-RED
docker logs -f node-red-mcp

# Logs do MCP Host
docker logs -f mcp-host

# Acesse os logs via interface web
# http://localhost:1899/admin/logs
```

## üîß Configura√ß√£o Avan√ßada

### Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Padr√£o | Obrigat√≥rio |
|----------|-----------|--------|-------------|
| `ADMIN_PASSWORD` | Senha do admin do Node-RED | `admin123` | ‚úÖ |
| `NODE_RED_ENABLE_PROJECTS` | Habilitar projetos | `false` | ‚ùå |
| `OPENAI_API_KEY` | Chave da API OpenAI | - | ‚ùå |

### Portas

- **1899**: Interface web do Node-RED
- **3000**: MCP Host API

### Volumes

- `/data`: Dados persistentes do Node-RED
  - Fluxos e configura√ß√µes
  - Node modules customizados
  - Logs e backups

## üìö Exemplos de Uso

### Exemplo 1: Chatbot Simples

```javascript
// Fluxo b√°sico de chatbot
[
  {
    "id": "chatbot-flow",
    "type": "tab",
    "label": "Chatbot Example",
    "nodes": [
      {
        "id": "trigger",
        "type": "inject",
        "name": "Start Chat",
        "props": {
          "payload": "Ol√°, como voc√™ pode me ajudar?"
        }
      },
      {
        "id": "mcp-tools",
        "type": "mcp-tools",
        "name": "AI Response",
        "config": {
          "prompt": "{{payload}}",
          "apiKey": "{{env.OPENAI_API_KEY}}"
        }
      },
      {
        "id": "debug",
        "type": "debug",
        "name": "Show Response"
      }
    ]
  }
]
```

### Exemplo 2: An√°lise de Dados

```javascript
// Fluxo para an√°lise de dados com LLM
[
  {
    "id": "data-analysis",
    "type": "tab",
    "label": "Data Analysis",
    "nodes": [
      {
        "id": "data-input",
        "type": "inject",
        "name": "Input Data",
        "props": {
          "payload": {
            "temperature": 25,
            "humidity": 60,
            "pressure": 1013
          }
        }
      },
      {
        "id": "analysis",
        "type": "mcp-tools",
        "name": "Analyze Data",
        "config": {
          "prompt": "Analise estes dados meteorol√≥gicos: {{JSON.stringify(payload)}}"
        }
      }
    ]
  }
]
```

## üîó Integra√ß√µes

### MCP Servers Suportados

- **Local MCP Server**: Inclu√≠do no projeto
- **Remote MCP Servers**: Via Smithery.io
- **Custom MCP Servers**: Sua pr√≥pria implementa√ß√£o

### LLMs Suportados

- **OpenAI GPT-4**: Configura√ß√£o padr√£o
- **OpenAI GPT-3.5**: Suportado
- **Claude**: Via configura√ß√£o customizada
- **Outros**: Via adaptadores MCP

## üìà Monitoramento

### M√©tricas Dispon√≠veis

- **CPU Usage**: Via Docker stats
- **Memory Usage**: Via Docker stats
- **Network Traffic**: Via Docker stats
- **Application Logs**: Via Docker logs

### Alertas

Configure alertas para:
- Uso de CPU > 80%
- Uso de mem√≥ria > 80%
- Erros de aplica√ß√£o
- Tempo de resposta > 5s

## üîÑ Backup e Restore

### Backup Autom√°tico

Para backup manual:

```bash
# Backup dos dados
docker exec node-red-mcp tar -czf /tmp/backup.tar.gz /data

# Download do backup
docker cp node-red-mcp:/tmp/backup.tar.gz ./backup.tar.gz
```

### Restore

```bash
# Upload do backup
docker cp ./backup.tar.gz node-red-mcp:/tmp/

# Restore dos dados
docker exec node-red-mcp tar -xzf /tmp/backup.tar.gz -C /
```

## ü§ù Contribui√ß√£o

1. **Fork** o projeto
2. **Crie uma branch** para sua feature (`git checkout -b feature/NovaFuncionalidade`)
3. **Commit** suas mudan√ßas (`git commit -m 'Adiciona nova funcionalidade'`)
4. **Push** para a branch (`git push origin feature/NovaFuncionalidade`)
5. **Abra um Pull Request**

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üÜò Suporte

### Canais de Ajuda

- **üìß Email**: [seu-email@exemplo.com](mailto:seu-email@exemplo.com)
- **üêõ Issues**: [GitHub Issues](https://github.com/moises-paschoalick/node-red-mcp-server/issues)
- **üí¨ Discord**: [Link do Discord](https://discord.gg/seu-servidor)
- **üìñ Wiki**: [Documenta√ß√£o Wiki](https://github.com/moises-paschoalick/node-red-mcp-server/wiki)

### Recursos √öteis

- [Node-RED Documentation](https://nodered.org/docs/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Railway Documentation](https://docs.railway.app/)
- [OpenAI API Documentation](https://platform.openai.com/docs/)

## üôè Agradecimentos

- [Node-RED](https://nodered.org/) - Plataforma de programa√ß√£o visual
- [Railway](https://railway.app/) - Plataforma de deploy
- [OpenAI](https://openai.com/) - Modelos de linguagem
- [MCP Community](https://modelcontextprotocol.io/) - Protocolo MCP

---

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela no reposit√≥rio!** 